<!DOCTYPE html>
<html>
<body>
<h1>Removing Undesirable Feature Contributions Using Out-of-Distribution Data</h1>
<p>Saehyung Lee (<A href="https://docs.google.com/document/d/1obF7IqcTU55PQfo22tXDCpVYx-vH93Z2_916B4DBWZQ/edit?usp=sharing">CV</A>), Changhwa Park, Hyungyu Lee, Jihun Yi, Jonghyun Lee, Sungroh Yoon</p>
<img src="thumbnail.png" alt="thumbnail">
<h2>Abstract</h2>
Several data augmentation methods deploy unlabeled-in-distribution (UID) data to bridge the gap between the training and inference of neural networks.<br>
However, these methods have clear limitations in terms of availability of UID data and dependence of algorithms on pseudo-labels.<br>
<strong>Herein, we propose a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues.</strong><br>
We show how to improve generalization theoretically using OOD data in each learning scenario and complement our theoretical analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. <br>
The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view.<br>
We also present the advantages of the proposed method through comparison with other data augmentation methods, which can be used in the absence of UID data.<br>
Furthermore, we demonstrate that the proposed method can further improve the existing state-of-the-art adversarial training.<br>
<h2>Algorithm</h2>
<img src="algo.png" alt="algorithm" width="1000" loading="lazy">
<h2>Results</h2>
<img src="table1.png" alt="table1" width="1000" loading="lazy">
<br>We created OOD datasets from the 80 Million Tiny Images dataset (Torralba et al.,2008) (<strong>80M-TI</strong>), using the work of Carmon et al. (2019) for CIFAR-10 and CIFAR-100, respectively.<br>
In addition, we resized (using a bilinear interpolation) ImageNet to dimensions of 64x64 and divided it into datasets containing 10 and 990 classes, respectively; these are called <strong>ImgNet10 and ImgNet990</strong>.
</body>
</html>
